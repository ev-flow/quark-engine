Quark Agent
===========

Introducing Quark's new member, the Quark Agent, the second AI assistant in the Quark team. This agent lets users get Quark reports using natural language, eliminating the need for terminal commands and making the analysis simple and user-friendly.

The Quark Agent integrates with LangChain, using OpenAI's large language model to act as a bridge between the natural language and the Quark APIs. LangChain defines the Quark APIs as tools that large language models can understand and use. This means users can run any Quark analysis using natural language by simply adding new tools as needed.

Showcase: Generate Summary Report with Quark Agent
--------------------------------------------------

Here's an example of using the Quark Agent. This agent can currently analyze `ovaa.apk <https://github.com/oversecured/ovaa>`__ and generate a :ref:`summary report <summary-report>`. See the details below.

Quick Start
~~~~~~~~~~~

1. Install the Quark Agent:

   .. code-block:: shell

      pip install quark-engine[QuarkAgent]

2. Prepare the rule and the sample:

   .. code-block:: shell

      git clone https://github.com/quark-engine/quark-script
      cd quark-script

3. Add your OpenAI API key to the environment:

   .. code-block:: python

      export OPENAI_API_KEY='your-api-key-here'

4. Run the Quark Agent:

   .. code-block:: shell

      quark-agent

5. Result:

.. image:: https://github.com/user-attachments/assets/3d7f6583-b558-4803-b8e1-c26535387139


Decode the Process
~~~~~~~~~~~~~~~~~~

Here, we explain what happens after running the Quark Agent.

Before processing user prompts, the Quark Agent uses a preset prompt to ensure the ``gpt-4o-mini`` model knows the format of a summary report.

.. code:: TEXT

    Preset prompt:

    When prompted to provide a summary report, follow this format:

        1. Print a newline character first to prevent formatting issues.
        2. "\x1b[1m\x1b[33m[!]\x1b[0m\x1b[0m WARNING: High Risk” - Display the risk level with each word capitalized.
        3. “\x1b[1m\x1b[36m[*]\x1b[0m\x1b[0m Total Score: 1” - Display the total score as a decimal Arabic numeral.
        4. The table immediately follows “Total Score” and should be inserted directly without using a code block. Keep any ANSI escape code in the table.

    Example:

    \x1b[1m\x1b[33m[!]\x1b[0m\x1b[0m WARNING: High Risk
    \x1b[1m\x1b[36m[*]\x1b[0m\x1b[0m Total Score: 1
    +------------------------+----------------------------+------------+-------+--------+
    | Filename               | Rule                       | Confidence | Score | Weight |
    +------------------------+----------------------------+------------+-------+--------+
    | writeContentToLog.json | Write contents to the log. | 40%        | 1     | 0.125  |
    +------------------------+----------------------------+------------+-------+--------+

    Ensure you adhere to this format when generating a summary report.

Then, we ask the Quark Agent to analyze the `ovaa.apk <https://github.com/oversecured/ovaa>`__ sample and generate a summary report. 

.. code:: TEXT

   User Prompt: Please analyze the sample “ovaa.apk” using Quark and the rule “constructCryptoGraphicKey.json.” After the analysis, print the summary report.

The ``initRuleObject``, ``initQuarkObject``, ``runQuarkAnalysis``, ``getSummaryReportTable``, ``getAnalysisResultRisk``, and ``getAnalysisResultScore`` APIs are treated as tools within LangChain, enabling them to be invoked through the ``gpt-4o-min`` model to analyze the `ovaa.apk <https://github.com/oversecured/ovaa>`__ sample. After the analysis, the model follows the preset prompt to generate the summary report.

.. image:: https://github.com/user-attachments/assets/5c70895d-e1c0-4f56-aedb-ffb0340edaa0

.. note::
   1. The summary report is generated by OpenAI's GPT model and is not always correct.
   2. Since LangChain currently does not support passing Python instances between tools, we temporarily use global variables to pass parameters between tools.
   3. Place the rules and samples in the working directory; the LLM will automatically find the files with matching names.
